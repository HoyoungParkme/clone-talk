당신은 Replit 환경에서 바로 실행/배포 가능한 “Last Talk” 풀스택 앱을 구현하는 시니어 엔지니어다.
목표는 카카오톡 대화 로그(.txt) 업로드 → 페르소나 리포트 생성/확정 → 전체 대화 임베딩(RAG) 저장(원본 삭제) → 실시간 채팅(스트리밍) 제공이다.
반드시 “보안/프라이버시(원본 삭제)”를 기본값으로 구현한다.

====================================================
0) 기술 스택/제약
====================================================
- Hosting: Replit
- Frontend: React (Vite) + TypeScript 권장, Kakao 스타일 채팅 UI
- Backend: FastAPI (Python 3.11+)
- Vector DB: ChromaDB(로컬 PersistentClient) 또는 FAISS(선택). 기본은 ChromaDB.
- Embedding: Jina Embedding API (REST)
- LLM: Anthropic Claude (Messages API, streaming 사용)
- Prompt Caching: Anthropic Prompt Caching 기능 사용 (cache_control). 캐시 TTL 기본 5분, 필요 시 1시간 옵션 고려. (공식 문서 참고) :contentReference[oaicite:0]{index=0}
- 원본 텍스트 파일은 “임베딩 완료 후 즉시 삭제”한다. (UI/서버 어디에도 원본을 저장하지 않음)
- MVP는 “단일 사용자/단일 브라우저 세션” 중심으로 구현하되, 코드 구조는 멀티유저 확장 가능하도록 설계.

====================================================
1) 산출물(반드시 생성)
====================================================
A. 리포지토리 구조(모노레포)
- /backend
- /frontend
- README.md (로컬 실행/배포/환경변수/동작설명)
- .env.example (백엔드 기준)
- (선택) /data 폴더: chroma 저장 경로 (gitignore)

B. 실행 방식(중요)
- 개발 모드: 프론트(Vite) + 백엔드(FastAPI) 동시 실행(한 번에 실행되게 스크립트 제공)
- 배포 모드: 백엔드가 프론트 빌드 정적 파일을 서빙하도록 구성(단일 프로세스 권장)

====================================================
2) 핵심 사용자 플로우(화면 기준)
====================================================
[화면1] 업로드 & 파싱 진행
1) 사용자가 카카오톡 대화 로그 .txt 업로드
2) 서버는 비동기 job 생성 → 진행률 제공
3) “최근 1000~2000줄” 기반 페르소나 리포트 생성

[화면2] 페르소나 리포트 확인/수정/확정
- 리포트(요약) + JSON(구조화) 둘 다 보여주고 사용자가 수정 가능
- 사용자가 “확정” 누르면:
  a) 전체 대화 chunking → 임베딩 → Chroma 저장
  b) 완료 후 업로드 원본 파일 즉시 삭제
  c) 페르소나 요약본(persona_profile.json 형태)은 저장(로컬 파일 또는 sqlite)

[화면3] 채팅
- 카카오톡 스타일 채팅 UI
- 사용자의 입력 → RAG 검색 top_k=3~5 → 페르소나 캐시(프롬프트 캐싱) + 컨텍스트 결합 → Claude 스트리밍 응답
- “능동적 에이전트 On/Off” 토글
  - On: 일정 간격으로 “안부 인사” 트리거(서버 스케줄러 or 프론트 폴링 방식 중 Replit에서 안정적인 방식 선택)
  - Off: 절대 선제 메시지 없음

====================================================
3) API 설계(반드시 이대로 구현)
====================================================
(1) 업로드/잡
- POST /api/upload
  - multipart/form-data: file (.txt)
  - response: { job_id }
- GET /api/jobs/{job_id}
  - response: { status: "queued|running|done|error", progress: 0~100, report?: PersonaReport, error?: string }

(2) 페르소나 확정 & 메모리 구축
- POST /api/persona/confirm
  - body: { job_id, persona_profile: PersonaProfile }
  - response: { ok: true }
  - 동작: 해당 job의 전체 대화를 임베딩하여 vector db에 적재, 완료 후 원본 삭제

(3) 채팅(스트리밍)
- POST /api/chat/stream
  - body: { session_id, message, agent_enabled: boolean }
  - response: Server-Sent Events(SSE) 또는 chunked streaming
  - event 예시:
    - event: token, data: {"text":"..."}
    - event: done, data: {"ok":true}

(4) 설정
- GET /api/settings
- POST /api/settings
  - body: { agent_enabled: boolean }

(5) 헬스
- GET /api/health -> { ok: true }

====================================================
4) 카카오톡 txt 파서(정규표현식/규칙)
====================================================
- 입력 파일은 다음과 같은 헤더를 가질 수 있음(예):
  - "2026년 1월 1일 오전 10:00, 나 : ... "
  - "2026. 1. 1. 오전 10:00, 철수 : ... "
  - 날짜 구분 라인(----- 2026년 1월 1일 -----) 등 변형 존재 가능
- 요구사항:
  1) 메시지 시작 라인을 regex로 탐지해서 (timestamp, speaker, text)로 파싱
  2) 다음 메시지 시작 전까지의 라인은 “멀티라인 메시지”로 이어붙이기
  3) 시스템 메시지/초대/나감/사진/이모티콘(파일) 등은 MVP에서는:
     - text가 비어있거나 특정 패턴이면 drop 또는 metadata로 분리
- 파서 출력 데이터 구조:
  Message = {
    "ts": "ISO8601 string",
    "speaker": "string",
    "text": "string",
    "line_no": int
  }

예시(의도)
- 원본:
  "2026년 1월 1일 오전 10:00, 나 : 오늘 커피 마셨어?"
  "응. 라떼"
  "2026년 1월 1일 오전 10:02, 철수 : 좋겠다"
- 파싱 결과:
  (10:00, 나, "오늘 커피 마셨어?\n응. 라떼")
  (10:02, 철수, "좋겠다")

====================================================
5) 페르소나 리포트 생성(Phase 1)
====================================================
- 최근 1000~2000줄(또는 메시지 300~600개 정도)만 사용
- Claude에 “분석 프롬프트”를 보내 PersonaReport 생성
- PersonaReport는 두 가지 형태 모두 생성:
  1) 사람이 읽는 요약 텍스트(말투/호칭/자주 쓰는 어미/자주 언급하는 주제/금기어/응답 길이 성향)
  2) 구조화 JSON(PersonaProfile)

PersonaProfile(JSON) 스키마 예시:
{
  "nickname_rules": ["철수야", "자기야" ...],
  "speech_style": {
    "endings": ["~니?", "~했어", "~지?" ...],
    "honorific_level": "informal|polite|mixed",
    "emoji_usage": "low|medium|high",
    "punctuation": "short|normal|many"
  },
  "favorite_topics": ["커피", "고양이", ...],
  "taboo_topics": ["..."],
  "response_length": "short|medium|long",
  "typical_patterns": [
    "질문으로 대화 이어감",
    "가끔 장난스러운 빈정거림"
  ],
  "few_shot_examples": [
    {"user":"오늘 뭐해?", "persona":"집에서 쉬고 있었지. 너는?"}
  ]
}

====================================================
6) 메모리 구축(RAG) (Phase 2)
====================================================
- chunking 규칙(권장):
  - 메시지 단위 기반으로 묶되, 300~800자 사이로 합치기(너무 짧으면 검색 품질 하락, 너무 길면 희석)
  - chunk metadata: {ts_range, speakers, message_ids, hash}
- 임베딩:
  - Jina Embeddings API 호출 (Authorization: Bearer, /v1/embeddings) :contentReference[oaicite:1]{index=1}
  - 입력은 chunk 텍스트 배열
- Vector store:
  - Chroma PersistentClient 사용(로컬 path 지정) :contentReference[oaicite:2]{index=2}
  - collection: "lasttalk_memories"
  - add(documents=[chunk_text], embeddings=[...], metadatas=[...], ids=[...])
- 적재 완료 후:
  - 업로드된 원본 파일을 os.remove로 삭제
  - 파싱된 “원문 전체 텍스트”도 메모리에서 참조 끊기기(변수 삭제), 디스크 저장 금지

====================================================
7) 대화 엔진(Phase 3) + Prompt Caching
====================================================
- 매 요청 시:
  1) user message 수신
  2) Chroma query로 top_k=3~5 유사 chunk 조회
  3) Claude 프롬프트 구성:
     - system: “너는 (이 페르소나)로 답한다. 사용자를 위로하되 과장하지 않는다. …”
     - persona_profile: 길고 고정적인 블록(캐시 대상)
     - retrieved memories: 이번 질문과 관련된 chunk 3~5개(가변)
     - user message
- Prompt caching:
  - persona_profile 블록에 cache_control: {"type":"ephemeral"} 설정해 캐시 재사용 :contentReference[oaicite:3]{index=3}
  - 캐시 TTL 기본 5분이며, 비활동 후 만료될 수 있으므로:
    - session_id별로 “마지막 대화 시각” 저장
    - 만료되었다고 판단되면 persona_profile을 다시 캐시 생성(첫 호출은 cache_write)
- 응답은 스트리밍으로 프론트에 전달(SSE 권장)

====================================================
8) 능동적 에이전트(On/Off) 구현(현실적인 MVP)
====================================================
Replit은 백그라운드 스케줄러가 환경에 따라 불안정할 수 있다.
따라서 MVP는 “프론트 폴링 기반”으로 구현한다.

- 프론트는 agent_enabled=true일 때:
  - 30~60초마다 GET /api/agent/poll?session_id=... 호출
- 서버는:
  - 마지막 인사 시각/사용자 마지막 활동 시각을 보고
  - 조건 충족 시 { should_send: true, message: "오늘은 어땠어?" } 반환
- 프론트는 should_send면 해당 메시지를 “상대(페르소나) 말풍선”으로 삽입(또는 서버가 chat/stream로 생성하도록 트리거)

====================================================
9) UI 요구사항(카카오 스타일)
====================================================
- 좌측: 설정(Agent On/Off), 페르소나 리포트 보기/수정, “메모리 구축 상태”
- 중앙: 채팅
- 상단 배너: “원본 파일은 임베딩 완료 후 자동 삭제됩니다” 고지 + 동의 체크박스(업로드 전)
- 채팅:
  - 내 말풍선/상대 말풍선 구분
  - 스트리밍 중에는 타이핑 인디케이터
- 업로드:
  - drag&drop
  - 진행률(progress bar)
  - 완료되면 자동으로 리포트 화면으로 이동

====================================================
10) 환경변수(.env) (반드시 .env.example 제공)
====================================================
BACKEND:
- ANTHROPIC_API_KEY=...
- ANTHROPIC_MODEL=... (예: claude-sonnet 계열)
- JINA_API_KEY=...
- JINA_EMBEDDINGS_MODEL=... (모델명)
- CHROMA_PATH=./data/chroma
- CORS_ORIGINS=http://localhost:5173 (dev)

====================================================
11) 구현 우선순위(작업 순서 지시)
====================================================
Step 1) 백엔드 골격(FastAPI) + health + CORS + 업로드 엔드포인트
Step 2) 카톡 파서 + job 상태/진행률(메모리 내 job store로 MVP)
Step 3) Claude 리포트 생성(Phase 1)
Step 4) 프론트 업로드/진행률/리포트 표시 + 수정 UI
Step 5) persona confirm → 임베딩 + Chroma 적재 + 원본 삭제(Phase 2)
Step 6) chat/stream + RAG 검색 + Claude 스트리밍(Phase 3)
Step 7) prompt caching 적용(cache_control)
Step 8) agent poll(능동적 인사) 토글/동작

====================================================
12) 완료 기준(Acceptance Criteria)
====================================================
- .txt 업로드 후 1분 내(테스트 파일 기준) 리포트 생성이 가능
- 리포트 확정 후:
  - Chroma에 벡터가 적재되고,
  - 서버 디스크에 원본 txt가 남지 않음
- 채팅에서 “과거 대화 조각”이 반영된 답변이 나옴(테스트 질문으로 검증)
  예: "우리 고양이 이름 뭐였지?" → 관련 chunk를 찾아 대답
- Prompt caching이 적용되어 동일 세션에서 반복 질의 시 캐시 히트가 가능(응답 메타에 cache_read 토큰이 잡히는지 로그로 확인) :contentReference[oaicite:4]{index=4}
- README에 실행 방법이 5분 안에 따라할 수 있게 정리되어 있음

====================================================
13) 코드 품질/보안(반드시)
====================================================
- 업로드 파일은 /tmp 또는 backend/temp에 저장 후 처리, 완료 시 삭제
- 원본/전체 텍스트를 DB에 저장 금지
- Chroma에는 chunk 텍스트가 documents로 들어가므로(민감 가능) MVP에서는:
  - “원본 삭제”를 하되, 사용자가 원하면 “chunk 텍스트도 저장하지 않고 요약만 저장” 모드(옵션)도 후속으로 확장 가능하게 TODO 남기기
- 로그에 원문 전체가 찍히지 않게 주의(길이 제한/마스킹)

====================================================
14) Replit에서 바로 실행되게 해라
====================================================
- backend requirements.txt / pyproject 중 하나 확정(간단히 requirements.txt 권장)
- frontend package.json + dev/build scripts
- 루트에 실행 스크립트 제공:
  - dev: (백엔드 8000 + 프론트 5173)
  - prod: 프론트 build 후 백엔드가 정적 서빙
- Replit Run 버튼을 누르면 dev 또는 prod 중 하나가 확실히 동작하도록 설정

====================================================
15) 마지막 출력 형식(너의 응답 방식)
====================================================
- 먼저 “생성한 폴더/파일 트리”를 보여줘
- 그 다음 핵심 파일들 코드를 모두 작성해줘(backend/main.py, parser, rag, anthropic client, frontend 주요 컴포넌트)
- 마지막에 실행 방법(Commands)과 테스트 시나리오 3개를 제공해줘.

시나리오 예시:
1) 업로드 → 리포트 생성 확인
2) 리포트 수정 → 확정 → 메모리 구축 완료 확인
3) “커피/고양이” 같은 키워드로 과거 대화가 회수되는지 질문

이 지시사항대로 즉시 코드를 생성하라. 추가 질문은 최소화하고, 합리적 기본값을 선택하라.
